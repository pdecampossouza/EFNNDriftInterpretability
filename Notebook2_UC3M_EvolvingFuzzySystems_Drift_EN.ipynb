{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fcfd53cf",
   "metadata": {},
   "source": [
    "# Day 2 — Evolving Fuzzy Systems for Data Streams & Concept Drift (UC3M Seminar)\n",
    "\n",
    "**Instructor:** Prof. Dr. Paulo Vitor de Campos Souza  \n",
    "**Venue:** Universidad Carlos III de Madrid (UC3M)  \n",
    "**Duration:** 5 hours (Day 2)\n",
    "\n",
    "---\n",
    "\n",
    "## Learning goals\n",
    "\n",
    "By the end of this notebook, students should be able to:\n",
    "\n",
    "1. Explain why *data streams* require **online** learning (predict-then-update).\n",
    "2. Recognize common **drift patterns** (abrupt, gradual, recurring).\n",
    "3. Train an **evolving neuro-fuzzy system** online and interpret its *evolution*:\n",
    "   - accuracy dynamics (including *rolling* accuracy),\n",
    "   - rule base growth/merging,\n",
    "   - feature relevance over time.\n",
    "4. Connect **drift detection** with **model adaptation**.\n",
    "5. Compare multiple **evolving fuzzy systems** from the `evolvingfuzzysystems` library under the same prequential protocol.\n",
    "\n",
    "> Execute cells sequentially. Each cell is designed to produce immediate visual feedback.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51e1e08b",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 0) Setup\n",
    "\n",
    "This notebook assumes you have in the same folder:\n",
    "\n",
    "- `evolving_nf_advanced.py` (your evolving neuro-fuzzy classifier used for didactic demonstrations)\n",
    "\n",
    "Later, for the final benchmark section, you also need:\n",
    "\n",
    "- `pip install evolvingfuzzysystems river scikit-learn pandas`\n",
    "\n",
    "If you do not have the library installed yet, you can skip the benchmark section and still learn everything from Parts 1–3.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bea2d699",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "np.random.seed(42)\n",
    "plt.rcParams[\"figure.figsize\"] = (8, 4)\n",
    "plt.rcParams[\"axes.grid\"] = True\n",
    "\n",
    "# Local model (didactic)\n",
    "from models.evolving_nf_advanced import EvolvingNeuroFuzzyAdvanced\n",
    "\n",
    "print(\"✓ Imports ok\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f8f9b6f",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 1) Why online learning? (Predict-then-update)\n",
    "\n",
    "In a **data stream**, observations arrive sequentially.  \n",
    "We cannot assume we can store all past data or retrain from scratch.\n",
    "\n",
    "A standard evaluation protocol is **prequential**:\n",
    "\n",
    "1. **Predict** $\\hat{y}_t$ using the current model\n",
    "2. Observe the true label $y_t$\n",
    "3. **Update** the model with $(x_t, y_t)$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3fe76bf",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 2) Synthetic streams with controlled drift\n",
    "\n",
    "We will create simple 2D classification streams where the decision boundary changes over time.\n",
    "\n",
    "Scenarios:\n",
    "- **No drift** (static)\n",
    "- **Abrupt drift**\n",
    "- **Gradual drift**\n",
    "- **Recurring concepts**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c8e0f5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Tuple, Dict\n",
    "\n",
    "def generate_static_linear(n_samples: int, random_state: int = 0) -> Tuple[np.ndarray, np.ndarray]:\n",
    "    rng = np.random.default_rng(random_state)\n",
    "    X = rng.normal(size=(n_samples, 2))\n",
    "    y = (X[:, 0] + 0.5 * X[:, 1] > 0.0).astype(int)\n",
    "    return X, y\n",
    "\n",
    "def generate_abrupt_drift(n_samples: int, random_state: int = 0) -> Tuple[np.ndarray, np.ndarray]:\n",
    "    rng = np.random.default_rng(random_state)\n",
    "    X = rng.normal(size=(n_samples, 2))\n",
    "    y = np.zeros(n_samples, dtype=int)\n",
    "    mid = n_samples // 2\n",
    "    y[:mid] = (X[:mid, 0] + 0.5 * X[:mid, 1] > 0.0).astype(int)\n",
    "    y[mid:] = (X[mid:, 0] - 0.8 * X[mid:, 1] > 0.3).astype(int)\n",
    "    return X, y\n",
    "\n",
    "def generate_gradual_drift(n_samples: int, random_state: int = 0) -> Tuple[np.ndarray, np.ndarray]:\n",
    "    rng = np.random.default_rng(random_state)\n",
    "    X = rng.normal(size=(n_samples, 2))\n",
    "    y = np.zeros(n_samples, dtype=int)\n",
    "\n",
    "    a_start, b_start = 0.5, 0.0\n",
    "    a_end, b_end = -0.8, 0.3\n",
    "\n",
    "    for t in range(n_samples):\n",
    "        alpha = t / max(n_samples - 1, 1)\n",
    "        a_t = (1 - alpha) * a_start + alpha * a_end\n",
    "        b_t = (1 - alpha) * b_start + alpha * b_end\n",
    "        y[t] = (X[t, 0] + a_t * X[t, 1] > b_t).astype(int)\n",
    "\n",
    "    return X, y\n",
    "\n",
    "def generate_recurring_concepts(n_samples: int, random_state: int = 0) -> Tuple[np.ndarray, np.ndarray]:\n",
    "    rng = np.random.default_rng(random_state)\n",
    "    X = rng.normal(size=(n_samples, 2))\n",
    "    y = np.zeros(n_samples, dtype=int)\n",
    "    third = n_samples // 3\n",
    "    y[:third] = (X[:third, 0] + 0.5 * X[:third, 1] > 0.0).astype(int)\n",
    "    y[third:2*third] = (X[third:2*third, 0] - 0.8 * X[third:2*third, 1] > 0.3).astype(int)\n",
    "    y[2*third:] = (X[2*third:, 0] + 0.5 * X[2*third:, 1] > 0.0).astype(int)\n",
    "    return X, y\n",
    "\n",
    "SCENARIOS = {\n",
    "    \"static_linear\": generate_static_linear,\n",
    "    \"abrupt_drift\": generate_abrupt_drift,\n",
    "    \"gradual_drift\": generate_gradual_drift,\n",
    "    \"recurring_concepts\": generate_recurring_concepts,\n",
    "}\n",
    "\n",
    "def drift_metadata(scenario_name: str, n: int):\n",
    "    meta = []\n",
    "    if scenario_name == \"abrupt_drift\":\n",
    "        meta.append({\"label\": \"drift\", \"start\": n//2, \"end\": n//2})\n",
    "    elif scenario_name == \"gradual_drift\":\n",
    "        meta.append({\"label\": \"start\", \"start\": n//4, \"end\": n//4})\n",
    "        meta.append({\"label\": \"end\", \"start\": 3*n//4, \"end\": 3*n//4})\n",
    "        meta.append({\"label\": \"drift-window\", \"start\": n//4, \"end\": 3*n//4})\n",
    "    elif scenario_name == \"recurring_concepts\":\n",
    "        meta.append({\"label\": \"A→B\", \"start\": n//3, \"end\": n//3})\n",
    "        meta.append({\"label\": \"B→A\", \"start\": 2*n//3, \"end\": 2*n//3})\n",
    "    return meta\n",
    "\n",
    "print(\"✓ Stream generators ready\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d3f0088",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.patches import Rectangle\n",
    "\n",
    "def _blend(c1, c2, a):\n",
    "    c1 = np.array(c1, float)\n",
    "    c2 = np.array(c2, float)\n",
    "    return tuple((1 - a) * c1 + a * c2)\n",
    "\n",
    "def plot_drift_schematics_scientific(\n",
    "    n_blocks=28,\n",
    "    cA=(0.12, 0.72, 0.78),   # A\n",
    "    cB=(0.98, 0.62, 0.14),   # B\n",
    "    show_labels=True,\n",
    "    line_alpha=0.9,\n",
    "    shade_alpha=0.12,\n",
    "):\n",
    "    \"\"\"\n",
    "    Draw schematic drift patterns with scientific markers:\n",
    "      - Sudden (abrupt): vertical line at drift point\n",
    "      - Gradual: shaded transition window + dashed center line\n",
    "      - Incremental: shaded transition window + dashed center line\n",
    "      - Recurring context: vertical lines at switches\n",
    "    \"\"\"\n",
    "\n",
    "    # ---------- define patterns + markers ----------\n",
    "    patterns = {}\n",
    "\n",
    "    # 1) Sudden: A then B\n",
    "    p = n_blocks // 2\n",
    "    sudden = [cA] * p + [cB] * (n_blocks - p)\n",
    "    patterns[\"Sudden drift\"] = dict(\n",
    "        cols=sudden,\n",
    "        vlines=[p],            # drift point\n",
    "        window=None\n",
    "    )\n",
    "\n",
    "    # 2) Gradual: probabilistic mixing in [start, end]\n",
    "    rng = np.random.default_rng(0)\n",
    "    start = n_blocks // 3\n",
    "    end = 2 * n_blocks // 3\n",
    "    gradual = []\n",
    "    for i in range(n_blocks):\n",
    "        if i < start:\n",
    "            gradual.append(cA)\n",
    "        elif i > end:\n",
    "            gradual.append(cB)\n",
    "        else:\n",
    "            a = (i - start) / max(1, (end - start))\n",
    "            gradual.append(cB if rng.random() < a else cA)\n",
    "\n",
    "    patterns[\"Gradual drift\"] = dict(\n",
    "        cols=gradual,\n",
    "        vlines=[(start + end) / 2],   # center marker\n",
    "        window=(start, end)           # transition window\n",
    "    )\n",
    "\n",
    "    # 3) Incremental: smooth color blend A -> B across entire horizon (or a window)\n",
    "    incremental = []\n",
    "    for i in range(n_blocks):\n",
    "        a = i / max(1, (n_blocks - 1))\n",
    "        incremental.append(_blend(cA, cB, a))\n",
    "\n",
    "    # you can set a window; here we mark the middle half as “transition”\n",
    "    inc_start = n_blocks * 0.25\n",
    "    inc_end = n_blocks * 0.75\n",
    "\n",
    "    patterns[\"Incremental drift\"] = dict(\n",
    "        cols=incremental,\n",
    "        vlines=[(inc_start + inc_end) / 2],\n",
    "        window=(inc_start, inc_end)\n",
    "    )\n",
    "\n",
    "    # 4) Recurring context: A -> B -> A\n",
    "    third = n_blocks // 3\n",
    "    recurring = [cA] * third + [cB] * third + [cA] * (n_blocks - 2 * third)\n",
    "    patterns[\"Recurring context\"] = dict(\n",
    "        cols=recurring,\n",
    "        vlines=[third, 2 * third],   # switches\n",
    "        window=None\n",
    "    )\n",
    "\n",
    "    # ---------- plot ----------\n",
    "    fig, axes = plt.subplots(4, 1, figsize=(10, 5.6), sharex=True)\n",
    "    plt.subplots_adjust(hspace=0.85)\n",
    "\n",
    "    for ax, (title, spec) in zip(axes, patterns.items()):\n",
    "        cols = spec[\"cols\"]\n",
    "        vlines = spec[\"vlines\"]\n",
    "        window = spec[\"window\"]\n",
    "\n",
    "        ax.set_title(title, loc=\"left\", fontsize=12)\n",
    "        ax.set_yticks([])\n",
    "        ax.set_xlim(0, n_blocks)\n",
    "        ax.set_ylim(0, 1)\n",
    "\n",
    "        # draw blocks\n",
    "        for i, col in enumerate(cols):\n",
    "            ax.add_patch(\n",
    "                Rectangle((i + 0.05, 0.2), 0.9, 0.6,\n",
    "                          facecolor=col, edgecolor=\"white\", linewidth=0.8)\n",
    "            )\n",
    "\n",
    "        # shaded drift window (if any)\n",
    "        if window is not None:\n",
    "            a, b = window\n",
    "            ax.axvspan(a, b, alpha=shade_alpha)\n",
    "\n",
    "        # drift/switch lines\n",
    "        for x in vlines:\n",
    "            ax.axvline(x, linestyle=\"--\", linewidth=1.5, alpha=line_alpha)\n",
    "\n",
    "        # optional A/B labels\n",
    "        if show_labels:\n",
    "            ax.text(0.02, 0.92, \"Concept A\", transform=ax.transAxes, fontsize=9)\n",
    "            ax.text(0.78, 0.92, \"Concept B\", transform=ax.transAxes, fontsize=9)\n",
    "\n",
    "        # clean spines\n",
    "        ax.spines[\"top\"].set_visible(False)\n",
    "        ax.spines[\"right\"].set_visible(False)\n",
    "        ax.spines[\"left\"].set_visible(False)\n",
    "\n",
    "    axes[-1].set_xlabel(\"Time\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Demo\n",
    "plot_drift_schematics_scientific()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a341d27",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_stream_2d(X, y, title=\"Stream (2D)\"):\n",
    "    n = len(y)\n",
    "    mid = n//2\n",
    "    plt.figure(figsize=(7, 4))\n",
    "    plt.scatter(X[:mid, 0], X[:mid, 1], s=18, alpha=0.7, label=\"first half\")\n",
    "    plt.scatter(X[mid:, 0], X[mid:, 1], s=18, alpha=0.7, label=\"second half\")\n",
    "    plt.title(title)\n",
    "    plt.xlabel(\"x1\")\n",
    "    plt.ylabel(\"x2\")\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "X_demo, y_demo = SCENARIOS[\"abrupt_drift\"](n_samples=600, random_state=0)\n",
    "plot_stream_2d(X_demo, y_demo, title=\"Abrupt drift stream (first half vs second half)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8d5d585",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 3) Prequential evaluation for the local evolving neuro-fuzzy model\n",
    "\n",
    "We track:\n",
    "- cumulative accuracy\n",
    "- rolling accuracy (best for drift visualization)\n",
    "- number of rules\n",
    "- feature relevance weights (if exposed by the model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da065378",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rolling_mean(x: np.ndarray, window: int = 200) -> np.ndarray:\n",
    "    x = np.asarray(x, float)\n",
    "    if window <= 1:\n",
    "        return x.copy()\n",
    "    out = np.full_like(x, np.nan, dtype=float)\n",
    "    c = np.cumsum(np.insert(x, 0, 0.0))\n",
    "    for i in range(window, len(x) + 1):\n",
    "        out[i-1] = (c[i] - c[i-window]) / window\n",
    "    for i in range(min(window-1, len(x))):\n",
    "        out[i] = np.mean(x[:i+1])\n",
    "    return out\n",
    "\n",
    "def prequential_nf(X: np.ndarray, y: np.ndarray, model_params=None, rolling_window: int = 200):\n",
    "    if model_params is None:\n",
    "        model_params = {}\n",
    "\n",
    "    n, d = X.shape\n",
    "    n_classes = len(np.unique(y))\n",
    "\n",
    "    model = EvolvingNeuroFuzzyAdvanced(n_features=d, n_classes=n_classes, **model_params)\n",
    "\n",
    "    correct = np.zeros(n, dtype=float)\n",
    "    acc = np.zeros(n, dtype=float)\n",
    "    rules_t = np.zeros(n, dtype=int)\n",
    "    featw_t = np.zeros((n, d), dtype=float)\n",
    "\n",
    "    for t in range(n):\n",
    "        x_t = X[t:t+1]\n",
    "        y_t = int(y[t])\n",
    "\n",
    "        if t == 0 or len(model.rules) == 0:\n",
    "            y_hat = 0\n",
    "        else:\n",
    "            y_hat = int(model.predict(x_t)[0])\n",
    "\n",
    "        correct[t] = 1.0 if y_hat == y_t else 0.0\n",
    "        acc[t] = correct[:t+1].mean()\n",
    "\n",
    "        model.partial_fit(x_t, np.array([y_t]))\n",
    "\n",
    "        rules_t[t] = len(model.rules)\n",
    "        try:\n",
    "            featw_t[t] = model.sep_buffer.compute_feature_weights()\n",
    "        except Exception:\n",
    "            featw_t[t] = np.nan\n",
    "\n",
    "    acc_roll = rolling_mean(correct, window=rolling_window)\n",
    "    return {\"model\": model, \"acc\": acc, \"acc_roll\": acc_roll, \"rules\": rules_t, \"featw\": featw_t, \"correct\": correct}\n",
    "\n",
    "def add_drift_markers(ax, meta):\n",
    "    for m in meta:\n",
    "        if m.get(\"label\") == \"drift-window\":\n",
    "            ax.axvspan(m[\"start\"], m[\"end\"], alpha=0.12, color=\"red\", label=\"drift window\")\n",
    "        else:\n",
    "            ax.axvline(m[\"start\"], linestyle=\"--\", color=\"red\", linewidth=1.2, alpha=0.9)\n",
    "\n",
    "def plot_nf_results(scenario_name: str, res: Dict, rolling_window: int):\n",
    "    n = len(res[\"acc\"])\n",
    "    meta = drift_metadata(scenario_name, n)\n",
    "    t = np.arange(n)\n",
    "\n",
    "    plt.figure(figsize=(10, 4))\n",
    "    plt.plot(t, res[\"acc\"], label=\"Cumulative prequential accuracy\")\n",
    "    plt.plot(t, res[\"acc_roll\"], label=f\"Rolling accuracy (window={rolling_window})\")\n",
    "    ax = plt.gca()\n",
    "    add_drift_markers(ax, meta)\n",
    "    plt.title(f\"Accuracy over time — {scenario_name}\")\n",
    "    plt.xlabel(\"time step\")\n",
    "    plt.ylabel(\"accuracy\")\n",
    "    plt.legend(ncol=2)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    plt.figure(figsize=(10, 3.6))\n",
    "    plt.plot(t, res[\"rules\"], label=\"#rules\")\n",
    "    ax = plt.gca()\n",
    "    add_drift_markers(ax, meta)\n",
    "    plt.title(f\"Rule base size over time — {scenario_name}\")\n",
    "    plt.xlabel(\"time step\")\n",
    "    plt.ylabel(\"#rules\")\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    plt.figure(figsize=(10, 3.6))\n",
    "    for j in range(res[\"featw\"].shape[1]):\n",
    "        plt.plot(t, res[\"featw\"][:, j], label=f\"feature {j+1}\")\n",
    "    ax = plt.gca()\n",
    "    add_drift_markers(ax, meta)\n",
    "    plt.title(f\"Feature relevance over time — {scenario_name}\")\n",
    "    plt.xlabel(\"time step\")\n",
    "    plt.ylabel(\"weight (normalized)\")\n",
    "    plt.legend(ncol=2)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "print(\"✓ Prequential + plotting ready\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15aad3e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- seminar-friendly defaults (fast + illustrative) ---\n",
    "n_samples = 2500\n",
    "rolling_window = 200\n",
    "\n",
    "model_params = dict(\n",
    "    alpha_add=0.25,\n",
    "    tau_merge=0.85,\n",
    "    lambda_sim=0.6,\n",
    "    buffer_size_similarity=150,\n",
    "    buffer_size_separability=200,\n",
    "    max_rules=40,\n",
    ")\n",
    "\n",
    "scenario_name = \"abrupt_drift\"  # try: static_linear, abrupt_drift, gradual_drift, recurring_concepts\n",
    "X, y = SCENARIOS[scenario_name](n_samples=n_samples, random_state=1)\n",
    "\n",
    "res = prequential_nf(X, y, model_params=model_params, rolling_window=rolling_window)\n",
    "plot_nf_results(scenario_name, res, rolling_window=rolling_window)\n",
    "\n",
    "print(\"Final cumulative accuracy:\", float(res[\"acc\"][-1]))\n",
    "print(\"Final number of rules:\", int(res[\"rules\"][-1]))\n",
    "print(\"Max number of rules:\", int(res[\"rules\"].max()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "065f336c",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 4) Drift detection (simple demonstration on the error stream)\n",
    "\n",
    "We feed the error stream (1 if wrong, 0 if correct) into a drift detector (ADWIN).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "175b5cb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    from river.drift import ADWIN\n",
    "    river_ok = True\n",
    "    print(\"✓ river is available (ADWIN)\")\n",
    "except Exception as e:\n",
    "    river_ok = False\n",
    "    print(\"river not available:\", repr(e))\n",
    "    print(\"Install with: pip install river\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00bb1d58",
   "metadata": {},
   "outputs": [],
   "source": [
    "from river.drift import ADWIN\n",
    "\n",
    "def detect_drifts_adwin(error_stream: np.ndarray, delta: float = 0.002):\n",
    "    if not river_ok:\n",
    "        return []\n",
    "    adwin = ADWIN(delta=delta)\n",
    "    detected = []\n",
    "\n",
    "    for t, err in enumerate(error_stream):\n",
    "        adwin.update(float(err))\n",
    "\n",
    "        # river versions differ: try the common flags\n",
    "        if getattr(adwin, \"drift_detected\", False) or getattr(adwin, \"change_detected\", False):\n",
    "            detected.append(t)\n",
    "\n",
    "    return detected\n",
    "\n",
    "if river_ok:\n",
    "    error_stream = 1.0 - res[\"correct\"]\n",
    "    detected = detect_drifts_adwin(error_stream, delta=0.2)\n",
    "    print(\"Detected drift points (ADWIN):\", detected[:10], \"...\" if len(detected) > 10 else \"\")\n",
    "\n",
    "    t = np.arange(len(res[\"acc_roll\"]))\n",
    "    plt.figure(figsize=(10, 4))\n",
    "    plt.plot(t, res[\"acc_roll\"], label=\"Rolling accuracy\")\n",
    "    for idx in detected[:20]:\n",
    "        plt.axvline(idx, color=\"red\", linewidth=2.0, alpha=0.5, linestyle=\":\")\n",
    "    plt.title(\"Rolling accuracy with ADWIN detections (dotted red lines)\")\n",
    "    plt.xlabel(\"time step\")\n",
    "    plt.ylabel(\"rolling accuracy\")\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00353472",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Part II — Benchmark with the `evolvingfuzzysystems` library (SOTA comparison)\n",
    "\n",
    "We compare multiple evolving fuzzy models under the same prequential protocol:\n",
    "\n",
    "- Warmup: `fit()` on the first samples\n",
    "- Then: predict on the next block, update via `evolve()` every `batch_evolve` samples\n",
    "- Normalize features to **[0,1]** (recommended by the library)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3850cf4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9e1f295",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Optional imports: evolvingfuzzysystems + river datasets ---\n",
    "try:\n",
    "    from river import datasets\n",
    "    from river.datasets import synth\n",
    "    from evolvingfuzzysystems.eFS import ePL, ePL_plus, exTS, Simpl_eTS, eMG, ePL_KRLS_DISCO\n",
    "    from evolvingfuzzysystems.classification import ENFS_Uni0\n",
    "    efs_ok = True\n",
    "    print(\"✓ evolvingfuzzysystems + river imported\")\n",
    "except Exception as e:\n",
    "    efs_ok = False\n",
    "    print(\"Optional libs not available:\", repr(e))\n",
    "    print(\"Install with: pip install evolvingfuzzysystems river\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b3817a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_stream_to_numpy(ds, n_max: int = 5000):\n",
    "    X_list = []\n",
    "    y_raw = []\n",
    "\n",
    "    it = ds.__iter__() if hasattr(ds, \"__iter__\") else iter(ds)\n",
    "    x0, y0 = next(it)\n",
    "    feat_names = list(x0.keys())\n",
    "\n",
    "    X_list.append(np.array([x0[f] for f in feat_names], float))\n",
    "    y_raw.append(y0)\n",
    "\n",
    "    for i, (x, y) in enumerate(it, start=1):\n",
    "        if i >= n_max:\n",
    "            break\n",
    "        X_list.append(np.array([x[f] for f in feat_names], float))\n",
    "        y_raw.append(y)\n",
    "\n",
    "    X = np.vstack(X_list).astype(float)\n",
    "    uniq = list(dict.fromkeys(y_raw))\n",
    "    enc = {lab: i for i, lab in enumerate(uniq)}\n",
    "    y_int = np.array([enc[v] for v in y_raw], int)\n",
    "    return X, y_int, uniq\n",
    "\n",
    "def coerce_pred_to_labels(y_hat, y_true):\n",
    "    y_true = np.asarray(y_true).reshape(-1)\n",
    "    labels = np.unique(y_true)\n",
    "    y_hat = np.asarray(y_hat).reshape(-1)\n",
    "\n",
    "    if np.issubdtype(y_hat.dtype, np.integer) or np.all(np.isclose(y_hat, np.rint(y_hat))):\n",
    "        y_hat_i = np.rint(y_hat).astype(int)\n",
    "        lo, hi = int(labels.min()), int(labels.max())\n",
    "        return np.clip(y_hat_i, lo, hi)\n",
    "\n",
    "    if len(labels) == 2:\n",
    "        return (y_hat >= 0.5).astype(int)\n",
    "\n",
    "    y_hat_i = np.rint(y_hat).astype(int)\n",
    "    lo, hi = int(labels.min()), int(labels.max())\n",
    "    return np.clip(y_hat_i, lo, hi)\n",
    "\n",
    "def update_model_batch(model, Xb, yb):\n",
    "    if hasattr(model, \"evolve\"):\n",
    "        try:\n",
    "            model.evolve(Xb, yb)\n",
    "        except Exception:\n",
    "            model.evolve(Xb, np.asarray(yb).reshape(-1, 1))\n",
    "    else:\n",
    "        try:\n",
    "            model.fit(Xb, yb)\n",
    "        except Exception:\n",
    "            model.fit(Xb, np.asarray(yb).reshape(-1, 1))\n",
    "\n",
    "def try_get_n_rules(model):\n",
    "    if hasattr(model, \"n_rules\") and callable(getattr(model, \"n_rules\")):\n",
    "        try:\n",
    "            return int(model.n_rules())\n",
    "        except Exception:\n",
    "            return np.nan\n",
    "    if hasattr(model, \"rules\"):\n",
    "        try:\n",
    "            return int(len(model.rules))\n",
    "        except Exception:\n",
    "            return np.nan\n",
    "    return np.nan\n",
    "\n",
    "def prequential_efs_warmup_evolve(model, X, y, warmup=200, batch_evolve=50, rolling_window=200):\n",
    "    X = np.asarray(X, float)\n",
    "    y = np.asarray(y, int)\n",
    "\n",
    "    scaler = MinMaxScaler()\n",
    "    Xs = scaler.fit_transform(X)\n",
    "\n",
    "    warmup = min(warmup, len(y))\n",
    "    model.fit(Xs[:warmup], y[:warmup])\n",
    "\n",
    "    y_true_seen = []\n",
    "    y_pred_seen = []\n",
    "    acc_batch = []\n",
    "    correct = []\n",
    "    rules = []\n",
    "\n",
    "    t = warmup\n",
    "    while t < len(y):\n",
    "        Xb = Xs[t:t+batch_evolve]\n",
    "        yb = y[t:t+batch_evolve]\n",
    "\n",
    "        y_hat = model.predict(Xb)\n",
    "        y_hat_lbl = coerce_pred_to_labels(y_hat, yb)\n",
    "\n",
    "        y_true_seen.extend(yb.tolist())\n",
    "        y_pred_seen.extend(y_hat_lbl.tolist())\n",
    "\n",
    "        corr = (y_hat_lbl.reshape(-1) == yb.reshape(-1)).astype(float)\n",
    "        correct.extend(corr.tolist())\n",
    "\n",
    "        acc_batch.append(accuracy_score(np.asarray(y_true_seen), np.asarray(y_pred_seen)))\n",
    "\n",
    "        update_model_batch(model, Xb, yb)\n",
    "        rules.append(try_get_n_rules(model))\n",
    "        t += batch_evolve\n",
    "\n",
    "    acc_batch = np.asarray(acc_batch, float)\n",
    "    correct = np.asarray(correct, float)\n",
    "    acc_roll = rolling_mean(correct, window=rolling_window)\n",
    "    return {\"acc_batch\": acc_batch, \"acc_roll\": acc_roll, \"rules\": np.asarray(rules, float)}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "528c7bf1",
   "metadata": {},
   "source": [
    "## 5) Synthetic benchmark stream (with known drift markers)\n",
    "\n",
    "We use a classic setup: **Agrawal → Agrawal** with a drift window.\n",
    "\n",
    "This is ideal for teaching because:\n",
    "- we know the drift location (`position`, `width`)\n",
    "- we can compare models consistently\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c673e1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "if efs_ok:\n",
    "    drift_position = 2500\n",
    "    drift_width = 1000\n",
    "\n",
    "    ds = synth.ConceptDriftStream(\n",
    "        stream=synth.Agrawal(seed=1),\n",
    "        drift_stream=synth.Agrawal(seed=2),\n",
    "        seed=42,\n",
    "        position=drift_position,\n",
    "        width=drift_width,\n",
    "    )\n",
    "\n",
    "    X_raw, y_int, labels = load_stream_to_numpy(ds, n_max=5000)\n",
    "    print(\"X:\", X_raw.shape, \"labels:\", labels, \"encoded:\", np.unique(y_int))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7fc783d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# Robust benchmark runner (ENFS_Uni0 + evolvingfuzzysystems eFS)\n",
    "# ============================================================\n",
    "import warnings\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from time import perf_counter\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# -----------------------------\n",
    "# 0) Clean console for seminar\n",
    "# -----------------------------\n",
    "warnings.filterwarnings(\"ignore\", category=RuntimeWarning)\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
    "np.seterr(over=\"ignore\", invalid=\"ignore\", divide=\"ignore\")\n",
    "\n",
    "\n",
    "# -----------------------------\n",
    "# 1) Helper utilities\n",
    "# -----------------------------\n",
    "def _ensure_1d_float(y):\n",
    "    \"\"\"Force y to be 1D float array (n,) to avoid 'sequence' issues inside some eFS implementations.\"\"\"\n",
    "    return np.asarray(y).ravel().astype(np.float64)\n",
    "\n",
    "def _ensure_1d_int(y):\n",
    "    \"\"\"Force y to be 1D int array (n,).\"\"\"\n",
    "    return np.asarray(y).ravel().astype(int)\n",
    "\n",
    "def _predict_score_scalar(model, x_row):\n",
    "    \"\"\"\n",
    "    Robust score extraction:\n",
    "    accepts scalar, 1d, 2d, list/tuple of arrays.\n",
    "    Always returns one float.\n",
    "    \"\"\"\n",
    "    yhat = model.predict(x_row)\n",
    "\n",
    "    if isinstance(yhat, (list, tuple)):\n",
    "        if len(yhat) == 0:\n",
    "            return 0.0\n",
    "        yhat = yhat[0]\n",
    "\n",
    "    arr = np.asarray(yhat)\n",
    "    if arr.size == 0:\n",
    "        return 0.0\n",
    "\n",
    "    return float(arr.ravel()[0])\n",
    "\n",
    "def _n_rules(model):\n",
    "    \"\"\"Best-effort rule count across different model APIs.\"\"\"\n",
    "    if hasattr(model, \"n_rules\") and callable(getattr(model, \"n_rules\")):\n",
    "        try:\n",
    "            return int(model.n_rules())\n",
    "        except Exception:\n",
    "            return np.nan\n",
    "    if hasattr(model, \"rules\"):\n",
    "        try:\n",
    "            return int(len(model.rules))\n",
    "        except Exception:\n",
    "            return np.nan\n",
    "    if hasattr(model, \"parameters\"):\n",
    "        # some models store rule params in a dataframe-like structure\n",
    "        try:\n",
    "            return int(len(model.parameters))\n",
    "        except Exception:\n",
    "            return np.nan\n",
    "    return np.nan\n",
    "\n",
    "def _rolling_mean(x, window):\n",
    "    x = np.asarray(x, float)\n",
    "    out = np.full_like(x, np.nan, dtype=float)\n",
    "    c = np.cumsum(np.insert(x, 0, 0.0))\n",
    "    for i in range(1, len(x) + 1):\n",
    "        j0 = max(0, i - window)\n",
    "        out[i - 1] = (c[i] - c[j0]) / (i - j0)\n",
    "    return out\n",
    "\n",
    "\n",
    "# -----------------------------\n",
    "# 2) Hybrid prequential protocol\n",
    "# -----------------------------\n",
    "def prequential_hybrid(\n",
    "    model,\n",
    "    X_raw,\n",
    "    y_int,\n",
    "    warmup=200,\n",
    "    batch_evolve=50,\n",
    "    rolling_window=250,\n",
    "    threshold=0.5,\n",
    "):\n",
    "    \"\"\"\n",
    "    Hybrid prequential evaluator:\n",
    "\n",
    "    - If model has evolve(): warmup fit + batch evolve (most eFS models)\n",
    "    - Else if model has partial_fit(): sample-by-sample updates (ENFS_Uni0-like)\n",
    "    - Else: fallback incremental batch fit\n",
    "\n",
    "    Returns:\n",
    "      acc_batch: accuracy measured every batch_evolve steps\n",
    "      acc_roll: rolling accuracy per sample (after warmup)\n",
    "      rules: rule count tracked every batch_evolve steps\n",
    "      correct_stream: 0/1 per sample correctness (after warmup)\n",
    "      mode: 'evolve' | 'partial_fit' | 'fit_batch'\n",
    "    \"\"\"\n",
    "\n",
    "    X_raw = np.asarray(X_raw, dtype=np.float64)\n",
    "    y_int = _ensure_1d_int(y_int)\n",
    "\n",
    "    # safety for NaN/Inf inputs\n",
    "    X_raw = np.nan_to_num(X_raw, nan=0.0, posinf=1.0, neginf=0.0)\n",
    "\n",
    "    # library recommends scaling to [0,1]\n",
    "    scaler = MinMaxScaler()\n",
    "    X = scaler.fit_transform(X_raw)\n",
    "\n",
    "    n = len(y_int)\n",
    "    warmup = min(warmup, n)\n",
    "\n",
    "    has_evolve = hasattr(model, \"evolve\") and callable(getattr(model, \"evolve\", None))\n",
    "    has_partial = hasattr(model, \"partial_fit\") and callable(getattr(model, \"partial_fit\", None))\n",
    "\n",
    "    # --- warmup ---\n",
    "    X_init = X[:warmup]\n",
    "    classes = np.unique(y_int)\n",
    "\n",
    "    if has_evolve:\n",
    "        mode = \"evolve\"\n",
    "        y_init = _ensure_1d_float(y_int[:warmup])\n",
    "        # try fit with (n,) then fallback (n,1)\n",
    "        try:\n",
    "            model.fit(X_init, y_init)\n",
    "        except Exception:\n",
    "            model.fit(X_init, y_init.reshape(-1, 1))\n",
    "\n",
    "    elif has_partial:\n",
    "        mode = \"partial_fit\"\n",
    "        # warmup sample-by-sample\n",
    "        for i in range(warmup):\n",
    "            xi = X_init[i:i+1]\n",
    "            yi = y_int[i:i+1]\n",
    "            if i == 0:\n",
    "                # some sklearn-like APIs require classes on first call\n",
    "                try:\n",
    "                    model.partial_fit(xi, yi, classes=classes)\n",
    "                except TypeError:\n",
    "                    model.partial_fit(xi, yi)\n",
    "            else:\n",
    "                model.partial_fit(xi, yi)\n",
    "\n",
    "    else:\n",
    "        mode = \"fit_batch\"\n",
    "        y_init = _ensure_1d_float(y_int[:warmup])\n",
    "        try:\n",
    "            model.fit(X_init, y_init)\n",
    "        except Exception:\n",
    "            model.fit(X_init, y_init.reshape(-1, 1))\n",
    "\n",
    "    # --- prequential loop ---\n",
    "    y_true_seen, y_pred_seen = [], []\n",
    "    correct_stream = []\n",
    "    acc_batch, rules_hist = [], []\n",
    "\n",
    "    bufX, bufy = [], []\n",
    "\n",
    "    for t in range(warmup, n):\n",
    "        x_t = X[t:t+1]\n",
    "        y_t = int(y_int[t])\n",
    "\n",
    "        # predict score -> binary label\n",
    "        score = _predict_score_scalar(model, x_t)\n",
    "        y_hat = int(score >= threshold)\n",
    "\n",
    "        y_true_seen.append(y_t)\n",
    "        y_pred_seen.append(y_hat)\n",
    "        correct_stream.append(1.0 if y_hat == y_t else 0.0)\n",
    "\n",
    "        # update model\n",
    "        if mode == \"evolve\":\n",
    "            bufX.append(x_t.ravel())\n",
    "            bufy.append(float(y_int[t]))\n",
    "            if len(bufy) >= batch_evolve:\n",
    "                X_block = np.vstack(bufX)\n",
    "                y_block = _ensure_1d_float(np.array(bufy))\n",
    "                try:\n",
    "                    model.evolve(X_block, y_block)\n",
    "                except Exception:\n",
    "                    model.evolve(X_block, y_block.reshape(-1, 1))\n",
    "                bufX, bufy = [], []\n",
    "\n",
    "        elif mode == \"partial_fit\":\n",
    "            model.partial_fit(x_t, np.array([y_t], dtype=int))\n",
    "\n",
    "        else:\n",
    "            bufX.append(x_t.ravel())\n",
    "            bufy.append(float(y_int[t]))\n",
    "            if len(bufy) >= batch_evolve:\n",
    "                X_block = np.vstack(bufX)\n",
    "                y_block = _ensure_1d_float(np.array(bufy))\n",
    "                try:\n",
    "                    model.fit(X_block, y_block)\n",
    "                except Exception:\n",
    "                    model.fit(X_block, y_block.reshape(-1, 1))\n",
    "                bufX, bufy = [], []\n",
    "\n",
    "        # log every batch\n",
    "        if (t - warmup + 1) % batch_evolve == 0:\n",
    "            acc_batch.append(accuracy_score(np.asarray(y_true_seen), np.asarray(y_pred_seen)))\n",
    "            rules_hist.append(_n_rules(model))\n",
    "\n",
    "    correct_stream = np.asarray(correct_stream, float)\n",
    "    acc_roll = _rolling_mean(correct_stream, rolling_window)\n",
    "\n",
    "    return {\n",
    "        \"acc_batch\": np.asarray(acc_batch, float),\n",
    "        \"acc_roll\": acc_roll,\n",
    "        \"rules\": np.asarray(rules_hist, float),\n",
    "        \"correct_stream\": correct_stream,\n",
    "        \"mode\": mode,\n",
    "    }\n",
    "\n",
    "\n",
    "# -----------------------------\n",
    "# 3) Run benchmark safely (skip failing models)\n",
    "# -----------------------------\n",
    "# Expect MODELS defined like:\n",
    "# MODELS = [(\"ENFS_Uni0\", lambda: ENFS_Uni0(...)), (\"ePL\", lambda: ePL()), ...]\n",
    "#\n",
    "# Also expect X_raw and y_int already prepared in your notebook.\n",
    "\n",
    "warmup = 200\n",
    "batch_evolve = 50\n",
    "rolling_window = 250\n",
    "threshold = 0.5\n",
    "\n",
    "if efs_ok:\n",
    "    import numpy as np\n",
    "    import matplotlib.pyplot as plt\n",
    "    from time import perf_counter\n",
    "\n",
    "    d = X_raw.shape[1]\n",
    "    n_classes = len(np.unique(y))\n",
    "\n",
    "    MODELS_REAL = [\n",
    "        (\"ENFS_Uni0\", lambda: ENFS_Uni0(\n",
    "            n_features=d, n_classes=n_classes,\n",
    "            lambda_ff=0.99, sim_threshold=0.95, max_rules=10,\n",
    "            random_state=42\n",
    "        )),\n",
    "        (\"ePL\", lambda: ePL()),\n",
    "        (\"exTS\", lambda: exTS()),\n",
    "        (\"eMG\", lambda: eMG()),\n",
    "    ]\n",
    "\n",
    "    warmup = 500\n",
    "    batch_evolve = 100\n",
    "    rolling_window = 400\n",
    "    threshold = 0.5  # if you see weird results, try 0.0 too\n",
    "\n",
    "    results_lib = {}\n",
    "    failed_real = []\n",
    "\n",
    "    for name, ctor in MODELS_REAL:\n",
    "        print(\"Running:\", name)\n",
    "        model = ctor()\n",
    "\n",
    "        t0 = perf_counter()\n",
    "        try:\n",
    "            results_lib[name] = prequential_hybrid(\n",
    "                model,\n",
    "                X_raw=X_raw,\n",
    "                y_int=y_int,\n",
    "                warmup=warmup,\n",
    "                batch_evolve=batch_evolve,\n",
    "                rolling_window=rolling_window,\n",
    "                threshold=threshold\n",
    "            )\n",
    "            dt = perf_counter() - t0\n",
    "            print(f\"  ✓ done in {dt:.2f}s | mode: {results_lib[name].get('mode','?')}\")\n",
    "\n",
    "        except Exception as e:\n",
    "            dt = perf_counter() - t0\n",
    "            print(f\"  ✗ Failed: {name} -> {repr(e)}  (skipping)\")\n",
    "            failed_real.append(name)\n",
    "\n",
    "    # ---- Plot rolling accuracy ----\n",
    "    plt.figure(figsize=(10, 4.2))\n",
    "    for name, resm in results_lib.items():\n",
    "        plt.plot(resm[\"acc_roll\"], label=f\"{name} ({resm.get('mode','?')})\")\n",
    "\n",
    "    plt.title(f\"Rolling accuracy (window={rolling_window}) — Elec2 (real stream)\")\n",
    "    plt.xlabel(\"time step (sample)\")\n",
    "    plt.ylabel(\"rolling accuracy\")\n",
    "    plt.legend(ncol=2)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    print(\"Failed models (real stream):\", failed_real)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dca139a",
   "metadata": {},
   "outputs": [],
   "source": [
    "if efs_ok:\n",
    "    # drift markers in batch-time coordinates (acc_batch is per batch after warmup)\n",
    "    t_batches = np.arange(len(next(iter(results_lib.values()))[\"acc_batch\"]))\n",
    "\n",
    "    drift_center_batch = max(0, (drift_position - warmup) // batch_evolve)\n",
    "    drift_start_batch  = max(0, ((drift_position - drift_width//2) - warmup) // batch_evolve)\n",
    "    drift_end_batch    = max(0, ((drift_position + drift_width//2) - warmup) // batch_evolve)\n",
    "\n",
    "    plt.figure(figsize=(10, 4.2))\n",
    "    for name, resm in results_lib.items():\n",
    "        plt.plot(t_batches, resm[\"acc_batch\"], label=name)\n",
    "\n",
    "    ax = plt.gca()\n",
    "    ax.axvspan(drift_start_batch, drift_end_batch, alpha=0.12, color=\"red\", label=\"drift window\")\n",
    "    ax.axvline(drift_center_batch, linestyle=\"--\", color=\"red\", linewidth=1.2, alpha=0.9)\n",
    "\n",
    "    plt.title(\"Cumulative prequential accuracy (batch-level) — ConceptDriftStream(Agrawal)\")\n",
    "    plt.xlabel(\"batch index\")\n",
    "    plt.ylabel(\"accuracy\")\n",
    "    plt.legend(ncol=2)\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1cf34bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "if efs_ok:\n",
    "    plt.figure(figsize=(10, 4.2))\n",
    "    for name, resm in results_lib.items():\n",
    "        plt.plot(resm[\"acc_roll\"], label=name)\n",
    "\n",
    "    ax = plt.gca()\n",
    "    ax.axvspan(drift_position - drift_width//2, drift_position + drift_width//2, alpha=0.12, color=\"red\", label=\"drift window\")\n",
    "    ax.axvline(drift_position, linestyle=\"--\", color=\"red\", linewidth=1.2, alpha=0.9)\n",
    "\n",
    "    plt.title(f\"Rolling accuracy (window={rolling_window}) — ConceptDriftStream(Agrawal)\")\n",
    "    plt.xlabel(\"time step (sample)\")\n",
    "    plt.ylabel(\"rolling accuracy\")\n",
    "    plt.legend(ncol=2)\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e18634c",
   "metadata": {},
   "outputs": [],
   "source": [
    "if efs_ok:\n",
    "    rows = []\n",
    "    for name, resm in results_lib.items():\n",
    "        rows.append({\n",
    "            \"model\": name,\n",
    "            \"final_acc_batch\": float(resm[\"acc_batch\"][-1]) if len(resm[\"acc_batch\"]) else np.nan,\n",
    "            \"mean_acc_batch\": float(np.mean(resm[\"acc_batch\"])) if len(resm[\"acc_batch\"]) else np.nan,\n",
    "            \"final_rules\": float(resm[\"rules\"][-1]) if len(resm[\"rules\"]) else np.nan,\n",
    "        })\n",
    "    df = pd.DataFrame(rows).sort_values(\"final_acc_batch\", ascending=False)\n",
    "    df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "187a4756",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 6) Optional real stream: Elec2\n",
    "\n",
    "Real streams do not provide explicit drift points, but rolling accuracy and drift detectors can still be used.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f62a39a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "if efs_ok:\n",
    "    ds_real = datasets.Elec2()\n",
    "    Xr, yr, labels_r = load_stream_to_numpy(ds_real, n_max=8000)\n",
    "    print(\"Elec2:\", Xr.shape, \"classes:\", labels_r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d564f997",
   "metadata": {},
   "outputs": [],
   "source": [
    "if efs_ok:\n",
    "    import numpy as np\n",
    "    import matplotlib.pyplot as plt\n",
    "    from time import perf_counter\n",
    "\n",
    "    d = Xr.shape[1]\n",
    "    n_classes = len(np.unique(yr))\n",
    "\n",
    "    MODELS_REAL = [\n",
    "        (\"ENFS_Uni0\", lambda: ENFS_Uni0(\n",
    "            n_features=d, n_classes=n_classes,\n",
    "            lambda_ff=0.99, sim_threshold=0.95, max_rules=10,\n",
    "            random_state=42\n",
    "        )),\n",
    "        (\"ePL\", lambda: ePL()),\n",
    "        (\"exTS\", lambda: exTS()),\n",
    "        (\"eMG\", lambda: eMG()),\n",
    "    ]\n",
    "\n",
    "    warmup = 500\n",
    "    batch_evolve = 100\n",
    "    rolling_window = 400\n",
    "    threshold = 0.5  # if you see weird results, try 0.0 too\n",
    "\n",
    "    results_real = {}\n",
    "    failed_real = []\n",
    "\n",
    "    for name, ctor in MODELS_REAL:\n",
    "        print(\"Running:\", name)\n",
    "        model = ctor()\n",
    "\n",
    "        t0 = perf_counter()\n",
    "        try:\n",
    "            results_real[name] = prequential_hybrid(\n",
    "                model,\n",
    "                X_raw=Xr,\n",
    "                y_int=yr,\n",
    "                warmup=warmup,\n",
    "                batch_evolve=batch_evolve,\n",
    "                rolling_window=rolling_window,\n",
    "                threshold=threshold\n",
    "            )\n",
    "            dt = perf_counter() - t0\n",
    "            print(f\"  ✓ done in {dt:.2f}s | mode: {results_real[name].get('mode','?')}\")\n",
    "\n",
    "        except Exception as e:\n",
    "            dt = perf_counter() - t0\n",
    "            print(f\"  ✗ Failed: {name} -> {repr(e)}  (skipping)\")\n",
    "            failed_real.append(name)\n",
    "\n",
    "    # ---- Plot rolling accuracy ----\n",
    "    plt.figure(figsize=(10, 4.2))\n",
    "    for name, resm in results_real.items():\n",
    "        plt.plot(resm[\"acc_roll\"], label=f\"{name} ({resm.get('mode','?')})\")\n",
    "\n",
    "    plt.title(f\"Rolling accuracy (window={rolling_window}) — Elec2 (real stream)\")\n",
    "    plt.xlabel(\"time step (sample)\")\n",
    "    plt.ylabel(\"rolling accuracy\")\n",
    "    plt.legend(ncol=2)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    print(\"Failed models (real stream):\", failed_real)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e3c39c8",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Wrap-up discussion prompts\n",
    "\n",
    "1. **When does drift matter the most?**\n",
    "2. **Accuracy vs interpretability trade-off** (rule base size).\n",
    "3. **Why evolving fuzzy systems?**  \n",
    "   online adaptation + inspectable rules.\n",
    "4. **How would you deploy this?**  \n",
    "   monitor accuracy, drift alarms, and rule evolution.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
